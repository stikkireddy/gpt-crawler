[
  {
    "title": "AI and machine learning on Databricks | Databricks Documentation",
    "url": "https://docs.databricks.com/aws/en/machine-learning",
    "html": "Skip to main content\nGet started\nDevelopers\nReference\nRelease notes\nResources\nEnglish\nAWS\nTRY DATABRICKS\nAI and machine learning\nAI and machine learning on Databricks\n\nThis article describes the tools that Mosaic AI (formerly Databricks Machine Learning) provides to help you build AI and ML systems. The diagram shows how various products on Databricks platform help you implement your end to end workflows to build and deploy AI and ML systems\n\nGenerative AI on Databricks​\n\nMosaic AI unifies the AI lifecycle from data collection and preparation, to model development and LLMOps, to serving and monitoring. The following features are specifically optimized to facilitate the development of generative AI applications:\n\nUnity Catalog for governance, discovery, versioning, and access control for data, features, models, and functions.\nMLflow for model development tracking.\nMosaic AI Gateway for governing and monitoring access to supported generative AI models and their associated model serving endpoints.\nMosaic AI Model Serving for deploying LLMs. You can configure a model serving endpoint specifically for accessing generative AI models:\nState-of-the-art open LLMs using Foundation Model APIs.\nThird-party models hosted outside of Databricks. See External models in Mosaic AI Model Serving.\nMosaic AI Vector Search provides a queryable vector database that stores embedding vectors and can be configured to automatically sync to your knowledge base.\nLakehouse Monitoring for data monitoring and tracking model prediction quality and drift using automatic payload logging with inference tables.\nAI Playground for testing generative AI models from your Databricks workspace. You can prompt, compare and adjust settings such as system prompt and inference parameters.\nFoundation Model Fine-tuning (now part of Mosaic AI Model Training) for customizing a foundation model using your own data to optimize its performance for your specific application.\nMosaic AI Agent Framework for building and deploying production-quality agents like Retrieval Augmented Generation (RAG) applications.\nMosaic AI Agent Evaluation for evaluating the quality, cost, and latency of generative AI applications, including RAG applications and chains.\nWhat is generative AI?​\n\nGenerative AI is a type of artificial intelligence focused on the ability of computers to use models to create content like images, text, code, and synthetic data.\n\nGenerative AI applications are built on top of generative AI models: large language models (LLMs) and foundation models.\n\nLLMs are deep learning models that consume and train on massive datasets to excel in language processing tasks. They create new combinations of text that mimic natural language based on their training data.\nGenerative AI models or foundation models are large ML models pre-trained with the intention that they are to be fine-tuned for more specific language understanding and generation tasks. These models are used to discern patterns within the input data.\n\nAfter these models have completed their learning processes, together they generate statistically probable outputs when prompted and they can be employed to accomplish various tasks, including:\n\nImage generation based on existing ones or utilizing the style of one image to modify or create a new one.\nSpeech tasks such as transcription, translation, question/answer generation, and interpretation of the intent or meaning of text.\nIMPORTANT\n\nWhile many LLMs or other generative AI models have safeguards, they can still generate harmful or inaccurate information.\n\nGenerative AI has the following design patterns:\n\nPrompt Engineering: Crafting specialized prompts to guide LLM behavior\nRetrieval Augmented Generation (RAG): Combining an LLM with external knowledge retrieval\nFine-tuning: Adapting a pre-trained LLM to specific data sets of domains\nPre-training: Training an LLM from scratch\nSupport for multimodal generative AI models​\n\nMultimodel generative AI models process and generate outputs across various data types, like text, images, audio, and video. Databricks supports a range of multimodal generative AI models that can be deployed via API or in batch mode, ensuring flexibility and scalability across all deployment scenarios:\n\nMultimodal models: Use hosted multimodal models like Llama 3.2 and external models like GPT-4o. See Supported foundation models on Mosaic AI Model Serving.\nFine-tuned and customized models: Fine-tune models to optimize them for specific use cases. See Foundation Model Fine-tuning.\nMachine learning on Databricks​\n\nWith Mosaic AI, a single platform serves every step of ML development and deployment, from raw data to inference tables that save every request and response for a served model. Data scientists, data engineers, ML engineers and DevOps can do their jobs using the same set of tools and a single source of truth for the data.\n\nMosaic AI unifies the data layer and ML platform. All data assets and artifacts, such as models and functions, are discoverable and governed in a single catalog. Using a single platform for data and models makes it possible to track lineage from the raw data to the production model. Built-in data and model monitoring saves quality metrics to tables that are also stored in the platform, making it easier to identify the root cause of model performance problems. For more information about how Databricks supports the full ML lifecycle and MLOps, see MLOps workflows on Databricks and MLOps Stacks: model development process as code.\n\nSome of the key components of the data intelligence platform are:\n\nTasks\n\n\t\n\nComponent\n\n\n\n\nGovern and manage data, features, models, and functions. Also discovery, versioning, and lineage.\n\n\t\n\nUnity Catalog\n\n\n\n\nTrack changes to data, data quality, and model prediction quality\n\n\t\n\nLakehouse Monitoring, Inference tables for custom models\n\n\n\n\nFeature development and management\n\n\t\n\nFeature engineering and serving.\n\n\n\n\nTrain models\n\n\t\n\nAutoML, Databricks notebooks\n\n\n\n\nTrack model development\n\n\t\n\nMLflow tracking\n\n\n\n\nServe custom models\n\n\t\n\nMosaic AI Model Serving.\n\n\n\n\nBuild automated workflows and production-ready ETL pipelines\n\n\t\n\nDatabricks Jobs\n\n\n\n\nGit integration\n\n\t\n\nDatabricks Git folders\n\nDeep learning on Databricks​\n\nConfiguring infrastructure for deep learning applications can be difficult. Databricks Runtime for Machine Learning takes care of that for you, with clusters that have built-in compatible versions of the most common deep learning libraries like TensorFlow, PyTorch, and Keras.\n\nDatabricks Runtime ML clusters also include pre-configured GPU support with drivers and supporting libraries. It also supports libraries like Ray to parallelize compute processing for scaling ML workflows and ML applications.\n\nDatabricks Runtime ML clusters also include pre-configured GPU support with drivers and supporting libraries. Mosaic AI Model Serving enables creation of scalable GPU endpoints for deep learning models with no extra configuration.\n\nFor machine learning applications, Databricks recommends using a cluster running Databricks Runtime for Machine Learning. See Create a cluster using Databricks Runtime ML.\n\nTo get started with deep learning on Databricks, see:\n\nBest practices for deep learning on Databricks\nDeep learning on Databricks\nReference solutions for deep learning\nNext steps​\n\nTo get started, see:\n\nTutorials: Get started with AI and machine learning\n\nFor a recommended MLOps workflow on Databricks Mosaic AI, see:\n\nMLOps workflows on Databricks\n\nTo learn about key Databricks Mosaic AI features, see:\n\nWhat is AutoML?\nFeature engineering and serving\nDeploy models using Mosaic AI Model Serving\nLakehouse Monitoring\nManage model lifecycle\nMLflow experiment tracking\nLast updated on Feb 5, 2025\nGenerative AI on Databricks\nWhat is generative AI?\nSupport for multimodal generative AI models\nMachine learning on Databricks\nDeep learning on Databricks\nNext steps\nSend us feedback·Privacy Notice·Terms of Use·Modern Slavery Statement·California Privacy·Your Privacy Choices \n© Databricks 2025. All rights reserved. Apache, Apache Spark, Spark and the Spark logo are trademarks of the Apache Software Foundation."
  }
]